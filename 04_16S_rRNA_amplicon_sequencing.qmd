---
title: "16S rRNA amplicon sequencing QC"
author: Laura Symul
date: today
format: 
   html:
     page-layout: full
     code-fold: true
     toc: true
     toc-location: left
     toc-depth: 5
     embed-resources: true
execute:
  cache: true # true refresh false
  warning: false
knitr:
  opts_chunk:
    out.width: "100%"
editor: source
---

:::callout-caution
This document only perform minimal QC at the moment - a lot of the upstream QC has been performed by Joseph Elsherbini and Johnathan Shih in Kwon's lab and Asavela at CAPRISA.


The main purpose of this document is to summarize at the species level, harmonize the data with the CRF data, and to prepare the data so that it can be integrated with other assays for downstream analyses.
:::


```{r}
#| warning: false

library(tidyverse)
library(magrittr)
library(gt)
library(patchwork)
library(SummarizedExperiment)
library(tidySummarizedExperiment)
library(phyloseq)
library(mia)


# tmp <- fs::dir_map("R scripts mg/", source)
tmp <- fs::dir_map("R scripts/", source)

theme_set(theme_light())
```

## Loading the data



```{r}
#| cache-lazy: false

data_source <- "real"

# TODO: change so it runs for different users.
VIBRANT_dropbox_dir <- 
  "/Users/laurasymul/Dropbox/Academia/Projects/VIBRANT Study Files/"


ps <- 
  readRDS(str_c(VIBRANT_dropbox_dir,"12_VIBRANT 16S/raw_merged_all_pools_ps_20250512.rds"))

ps

```

Sample data:

```{r}

ps@sam_data |> 
  as.data.frame() |> 
  as_tibble() |> 
  glimpse()

```

Taxonomic table:

```{r}

ps@tax_table |> as.data.frame() |> as_tibble() |> glimpse()

```


## Data cleaning and harmonization

### Dimensions and sparsity

The `phyloseq` object contains counts for `r nrow(ps@sam_data)` samples and `r nrow(ps@tax_table)` ASVs.

```{r}
#| cache-lazy: false
counts <- ps@otu_table |> as.matrix()
prop_0 <- mean(counts == 0)
```


This is a very large number of ASVs and most of them are not present in most samples as the proportion of 0s in the count table is `r round(100*prop_0, 2)`%.

```{r}

ASV_stats <- 
  tibble(
    mean_counts = colMeans(counts),
    n_non_zero = colSums(counts > 0),
    f_non_zero = n_non_zero / nrow(counts),
    max_counts = apply(counts, 2, max)
  )

```


```{r}
#| fig-width: 8
#| fig-height: 5

ASV_stats |> ggplot() + aes(x = mean_counts) + geom_histogram(bins = 30) +
  scale_x_log10(n.breaks = 10) +
  labs(x = "Mean counts (log scale)", y = "Number of ASVs") +
  
  
ASV_stats |> ggplot() + aes(x = max_counts) + geom_histogram(bins = 30) +
    scale_x_log10(n.breaks = 8) +
  labs(x = "Max number of counts (log scale)", y = "Number of ASVs") +
  
ASV_stats |> ggplot() + aes(x = f_non_zero) + geom_histogram(bins = 30) +
    scale_x_log10(n.breaks = 6) +
  labs(x = "Proportion of samples with non-zero counts(log scale)", y = "Number of ASVs") +
  
  plot_layout(nrow = 2)
  
```

`r (ASV_stats$n_non_zero == 1) |> mean() |> magrittr::multiply_by(100) |> round(2)`% of ASVs are present (non-zero counts) in only 1 sample.


```{r}
rm(counts, ASV_stats)
```



### Creation a of `SummarizedExperiment` object


To facilitate data harmonization and cleaning, we transform the `phyloseq` object to a `SummarizedExperiment` object **summarized at the species level** to reduce the size of the object.  


```{r}
#| eval: false

# throws an error
ps_agg <- ps |> tax_glom("Species") 

```


:::callout-note
At a later stage, we could keep the full ASV counts, but at this stage, for most analyses, the species level is sufficient.
:::


```{r}

make_se_from_ps <- function(ps) {
  
  # ROWDATA (Tax table)
  asv_tax_table <- 
    ps@tax_table |> 
    as.data.frame() |>
    rownames_to_column("ASV_sequence") |> 
    mutate(ASV_nb = row_number()) |>
    group_by(Species) |> 
    mutate(ASV_id = str_c(Species, " (ASV", ASV_nb |> str_pad(width = 6, pad = "0"),")")) |> 
    ungroup() |> 
    mutate(rownames = ASV_id) |> 
    column_to_rownames("rownames") |> 
    relocate(ASV_sequence, .after = ASV_id)  |> 
    janitor::clean_names()
  
  # (asv_tax_table$species |> unique() |> length()) == (asv_tax_table |> dplyr::count(domain, phylum, class, order, family, genus, species) |> nrow())
  
  se_rowdata <- 
    asv_tax_table |> 
    group_by(domain, phylum, class, order, family, genus, species) |> 
    summarize(
      n_asv = n(),
      asv_ids = str_c(asv_id, collapse = ", "),
      .groups = "drop"
    )
  
  # COLDATA (Sample data)
  se_coldata <-
    ps@sam_data |> 
    as.data.frame() |> 
    as_tibble() |>  # weird trick because of the sticky `phyloseq` attribute
    as.data.frame() |> 
    set_rownames(rownames(ps@sam_data))
  
  coldata_dictionary <- 
    tibble(
      original_name = se_coldata |> colnames()
    )
  
  se_coldata <- se_coldata |> janitor::clean_names()
  se_coldata <- se_coldata |> dplyr::rename(visit_code_ps = visit_code)
  
  coldata_dictionary <- 
    coldata_dictionary |> bind_cols(name = colnames(se_coldata))
  
  se_coldata <- se_coldata |> mutate(sample_id_16s = rownames(se_coldata)) 
   

  # ASSSAY
  raw_counts <- ps@otu_table |> as.matrix()
  class(raw_counts) <- "matrix"
  raw_counts <- raw_counts |> t()
  rownames(raw_counts) <- asv_tax_table$asv_id
  
  tmp <- 
    raw_counts |> 
    as.data.frame() |>
    mutate(species = asv_tax_table$species) 
  
  counts_assay <- 
    tmp |> 
    group_by(species) |> 
    summarize(across(everything(), sum)) |> 
    column_to_rownames("species")
  
  # SummarizedExperiment
  
  se <- SummarizedExperiment(
    assays = list(
      counts = counts_assay,
      rel_ab = t(t(counts_assay) / colSums(counts_assay))
    ),
    rowData = se_rowdata,
    colData = se_coldata,
    metadata = list(
      name = "VIBRANT 16S rRNA amplicon sequencing",
      data = today(),
      coldata_dictionary = coldata_dictionary,
      asv_tax_table = asv_tax_table
    )
  )
  
  
  # reordering taxa
  taxa_order <- 
    se |> as_tibble() |> 
    group_by(.feature) |> summarize(mean_rel_ab = mean(rel_ab)) |> 
    arrange(-mean_rel_ab) |> pull(.feature)
  
  se <- se[taxa_order, ]
  
  
  se
}

```

```{r}
se_16S <- make_se_from_ps(ps)
```


```{r}
se_16S
```

We renamed the columns in the sample data:

```{r}
se_16S@metadata$coldata_dictionary |> gt()
```




### Harmonization of sample and participant IDs

We have data for the following samples:

```{r}
#| fig-height: 10
#| fig-width: 15

se_16S@colData |> 
  as.data.frame() |> 
  ggplot() +
  aes(x = patient_id, y = visit_code_ps) +
  geom_point() +
  facet_grid(. ~ site, scales = "free", space = "free") +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
  )

```

We see that we'll have to harmonize the `patient_id` and `visit_code` columns. From harmonized participant ID, we'll be able to impute the site location.


```{r}

se_16S@colData <- 
  se_16S@colData |> 
  as.data.frame() |> 
  mutate(
    pid = 
      patient_id |> 
      str_remove_all("_") |> 
      str_remove_all("-") |> 
      str_replace_all("^68","068") 
  ) |> 
  DataFrame()

```


```{r}

se_16S@colData |> 
  as.data.frame() |> 
  mutate(pid_length = str_length(pid)) |> 
  filter(pid_length != 9) |> 
  dplyr::count(patient_id, pid) |> 
  gt(
    caption = "Samples with non-standard participant IDs"
  )

```


:::callout-note
As in the metagenomics, there were 7 samples from a participant from another study (starting by (0)98). 
:::

The rest looks legit. 

We next clean the `visit_code_ps`

```{r}
#| eval: false

 se_16S@colData |> 
  as.data.frame() |> 
  dplyr::count(visit_code_ps)

```



```{r}

se_16S@colData <- 
  se_16S@colData |> 
  as.data.frame() |> 
  mutate(
    visit_code = 
      visit_code_ps |> 
      str_replace("V7", "1700") |> 
      str_replace("V8", "1900") |>
      str_replace("V9", "2120") |> 
      str_pad(width = 4, pad = "0") 
  ) |> 
  DataFrame()

```


We also create new columns for the `sample_type` and `control_type` 


```{r}

se_16S@colData <- 
  se_16S@colData |> 
  as.data.frame() |> 
  mutate(
    sample_type = 
      case_when(
        str_detect(pid, "^068") ~ "Clinical sample",
        str_detect(pid, "98") ~ "Clinical sample (other study)",
        str_detect(pid, "Amplification NEG control") | str_detect(sample_id, "Amplification_NEG_control") ~ "Amplification negative control",
        str_detect(pid, "Amplification POS control") | str_detect(sample_id, "Amplification_POS_control") ~ "Amplification positive control",
        str_detect(pid, "Mock") | str_detect(sample_id, "Mock") ~ "Positive control",
        str_detect(pid, "water") | str_detect(pid, "Unused") | str_detect(sample_id, "water") | str_detect(sample_id, "Unused")  ~ "Negative control",
      ),
    control_type = 
      case_when(
        str_detect(sample_type, "Clinical") ~ "",
        str_detect(sample_id, "Mock1") ~ "Mock 1",
        str_detect(pid, "Mock") ~ pid,
        str_detect(pid, "water") | str_detect(sample_id, "water") ~ "Nuclease-free water",
        str_detect(pid, "Unused") | str_detect(sample_id, "Unused")  ~ "Unused swab + C2",
        TRUE ~ sample_type
      )
  ) |> 
  DataFrame()

```

```{r}

se_16S@colData |> 
  as.data.frame() |> 
  dplyr::count(sample_type, control_type) |> 
  gt()

```


```{r}

se_16S$pid <- ifelse(!(se_16S$sample_type %in% c("Clinical sample", "Clinical sample (other study)")), NA_character_, se_16S$pid)

```





We also create a column `ext_lib_plate` that contains the extraction library plate (from Sinaye) so that we'll be able to compare the controls between 16S and metagenomics (the barcodes do not seem to match those provided by Michael - there, the controls barcode start with "EQ")

:::callout-note
Does that "EQ"-starting barcodes sound familiar or not at all?
:::

> TODO



### Number of observation per `pid` and `visit_code`

After harmonizing the `pid` and `visit_code`, we notice that a number of participants have two samples per visit.

All of these "replicates" are from "pool10" which, I assume, was a bunch of samples that had to be re-sequenced.


```{r}


replicates <- 
  se_16S@colData |> 
  as.data.frame() |> 
  as_tibble() |> 
  filter(sample_type == "Clinical sample")

replicates |> 
  dplyr::count(pid, visit_code, name = "n samples per participant x visit") |> 
  dplyr::count(`n samples per participant x visit`, name = "occurence") |> 
  gt()

# se_16S@colData |> 
#   as.data.frame() |> 
#   as_tibble() |> 
#   filter(sample_type == "Clinical sample") |> 
#   dplyr::count(patient_id, visit_code_ps) |> 
#   dplyr::count(n)


replicates <- 
  replicates |>
  group_by(pid, visit_code) |> arrange(visit_code) |>  mutate(n = n(), rep_nb = row_number()) |> ungroup() |> 
  filter(n > 1) |> 
  select(sample_id, patient_id, pid, visit_code_ps, visit_code, rep_nb, pool) |> 
  arrange(pid, visit_code_ps) 

replicates |> 
  dplyr::count(rep_nb, pool) |> 
  gt()

```


We'll do a comparison of the composition of these samples below.

```{r}

se_16S@colData$resequenced <- "No"
se_16S@colData$resequenced[se_16S@colData$sample_id %in% replicates$sample_id[replicates$pool != "pool10"]] <- "Yes"
se_16S@colData$resequenced[se_16S@colData$sample_id %in% replicates$sample_id[replicates$pool == "pool10"]] <- "2nd sequencing"

se_16S@colData$resequenced <- se_16S@colData$resequenced |> factor(levels = c("No", "Yes", "2nd sequencing"))

```


### Matching `pid` and `visit_code` with the CRF data


:::callout-caution
Below, I load a list of all visits for all participants as found in the CRF data - this is **NOT** based on CRF-based specimen collection data.
:::

> TODO: change so that it uses the "expected" data based on the weekly specimen collection data (CRF 35) and the home swab collection data (CRF 47).


```{r}

load("/Users/laurasymul/OneDrive - UCL/Academia/Research/VIBRANT clinical data UCLouvain/Data processed/2025-05-14/visits_summary.RData", verbose = TRUE)
v <- v |> dplyr::rename(visit_code_crf = visit_code) |> mutate(pid = str_c("068", pid))

```
```{r}
v <- 
  v |> 
  mutate(visit_code = visit_code_crf |> as.character() |> str_pad(width = 4, pad = "0")) 
```

```{r}
#| fig-height: 10
#| fig-width: 15
#| eval: false

v |> 
  ggplot() +
  aes(x = pid, y = visit_code, col = randomized) +
  geom_point() +
  facet_grid(. ~ location + randomized, scales = "free", space = "free") +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
  ) + 
  ggtitle("CRF data")

```


```{r}

matched <- 
  dplyr::full_join(
    se_16S@colData |> 
      as.data.frame() |> 
      filter(sample_type == "Clinical sample") |> 
      as_tibble() |> 
      select(pid, visit_code, patient_id, visit_code_ps, sample_id, site) |> 
      mutate(has_16S_data = TRUE),
    v |> select(pid, visit_code) |>  mutate(has_CRF_data = TRUE),
    by = join_by(pid, visit_code)
  ) |> 
  mutate(
    has_16S_data = has_16S_data |> replace_na(FALSE),
    has_CRF_data = has_CRF_data |> replace_na(FALSE)
  ) |> 
  dplyr::left_join(
    v |> select(pid, location, met_eligibility, randomized) |> distinct() |> mutate(pid_in_CRFs = TRUE),
    by = join_by(pid)
  ) |> 
  mutate(
    pid_in_CRFs = pid_in_CRFs |> replace_na(FALSE)
  )

```


```{r}

matched |> 
  dplyr::count(has_16S_data, has_CRF_data, pid_in_CRFs, randomized, name = "n entries") |> 
  gt()

```


```{r}
#| fig-width: 21
#| fig-height: 10

matched |> 
  ggplot() +
  aes(x = pid, y = visit_code, col = has_16S_data, shape = has_CRF_data) +
  geom_point() +
  facet_grid(. ~ location + ifelse(randomized,"Randomized", "Not randomized"), scales = "free", space = "free") +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
  ) + 
  scale_shape_manual(values = c(1, 16)) +
  ggtitle("matched data")

```

Let's focus on 

- "Clinical samples" in the 16S data that we do not have in the CRFs
- Randomized participants with non-matching visits in the 16S data.

#### Participant ID not in the CRFs

```{r}

matched |> 
  filter(is.na(location)) |> 
  dplyr::count(pid, patient_id) |> 
  gt()

```

These are likely "test" participants.

#### Randomized participants with non-matching visits in the 16S data


```{r}
#| fig-width: 15
#| fig-height: 9

matched |> 
  filter(randomized) |> 
   ggplot() +
  aes(x = pid, y = visit_code, col = has_16S_data, shape = has_CRF_data) +
  geom_point(size = 1.5) +
  facet_grid(. ~ location + ifelse(randomized,"Randomized", "Not randomized"), scales = "free", space = "free") +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
  ) + 
  scale_shape_manual(values = c(1, 16)) +
  ggtitle("matched data")

```

We have a quite ok match. Some observations around the mismatches:

- We see a few examples of likely mis-labelled visits (*e.g.,* around the screening visits)

- and a few "missing" 16S at visits where swabs are not expected (*e.g.* 2121 or 1511).

- One SA participant has a whole week of missed swabs, but another week without crfs but with swabs.

- A few US participants were supposed to collect swabs but likely did not (to check once the "daily specimen collection CRF" is cleaned)


Overall, it looks fine.

:::callout-note
We should probably review this with the team once the CRF data have been cleaned and QCed.
:::


## Exploratory & QC analyses

### Total number of counts per sample.

```{r}

se_16S@colData$total_counts <- colSums(assay(se_16S, "counts"))

```


```{r}
#| fig-width: 8
#| fig-height: 5

se_16S@colData |> 
  as.data.frame() |> 
  ggplot() +
  aes(x = total_counts, fill = control_type) +
  geom_histogram(bins = 30) +
  scale_x_log10(n.breaks = 8) +
  labs(x = "Total counts (log scale)", y = "Nb of samples") +
  facet_grid(sample_type ~ ., scales = "free") +
  theme(strip.text.y = element_text(angle = 0))

```

```{r}
#| fig-width: 8
#| fig-height: 5

se_16S@colData |> 
  as.data.frame() |> 
  filter(sample_type == "Clinical sample") |> 
  ggplot() +
  aes(x = resequenced, y = total_counts, fill = resequenced) +
  # geom_histogram(bins = 30) +
  geom_violin(alpha = 0.3, col = "transparent", scale = "width") +
  ggbeeswarm::geom_quasirandom(alpha = 0.5, size = 0.1) +
  geom_path(aes(group = interaction(pid, visit_code)), alpha = 0.1) +
  scale_y_log10(n.breaks = 8) +
  guides(fill = "none") +
  labs(x = "Re-sequenced", y = "Total counts (log scale)") +
  ggtitle("Clinical samples only")

```


```{r}
#| fig-width: 8
#| fig-height: 5

tmp <- 
  se_16S@colData |> 
  as.data.frame() |> 
  filter(!is.na(visit_code)) |> 
  group_by(visit_code) |> mutate(n = n()) |> ungroup() |> 
  filter(n > 20) |> 
  mutate(visit_code = visit_code |> factor()) |> 
  arrange(pid, visit_code)

tmp |> 
  ggplot() +
  aes(y = total_counts, x = visit_code, fill = visit_code, col = visit_code) +
  # geom_path(aes(group = pid), alpha = 0.15) +
  geom_violin(draw_quantiles = 0.5, alpha = 0.5) + # fill = "gray", 
  scale_y_log10(n.breaks = 10) +
  guides(fill = "none", col = "none") +
  labs(y = "Total counts (log scale)", x = "Visit") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

```

### Controls

#### Negative controls

```{r}
#| fig-width: 12
#| fig-height: 5

tmp <- 
  se_16S |> 
  filter(sample_type == "Negative control") |> 
  as_tibble() |> 
  group_by(.feature) |>
  mutate(max_rel_ab = max(rel_ab)) |> 
  ungroup() |> 
  filter(max_rel_ab > 0.1)

tmp |> 
  ggplot() +
  aes(x = sample_id, y = rel_ab, fill = .feature) +
  geom_col() +
  scale_fill_manual(
    str_c("Top ", tmp$.feature |> unique() |> length(), " taxa (based on max rel. ab.)"), 
    breaks = tmp$.feature |> unique(), 
    values = tmp$.feature |> unique() |> get_taxa_colors()
  ) +
  facet_grid(. ~ control_type, scales = "free_x", space = "free_x") +
  theme(
    strip.text.y = element_text(angle = 0),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    )
  
```


#### Amplification negative controls

```{r}
#| fig-width: 12
#| fig-height: 5

tmp <- 
  se_16S |> 
  filter(sample_type == "Amplification negative control") |> 
  as_tibble() |> 
  group_by(.feature) |>
  mutate(max_rel_ab = max(rel_ab)) |> 
  ungroup() |> 
  filter(max_rel_ab > 0.2)

tmp |> 
  ggplot() +
  aes(x = sample_id, y = rel_ab, fill = .feature) +
  geom_col() +
  scale_fill_manual(
    str_c("Top ", tmp$.feature |> unique() |> length(), " taxa (based on max rel. ab.)"), 
    breaks = tmp$.feature |> unique(), 
    values = tmp$.feature |> unique() |> get_taxa_colors()
  ) +
  facet_grid(. ~ control_type, scales = "free_x", space = "free_x") +
  theme(
    strip.text.y = element_text(angle = 0),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    )
  
```


#### Amplification positive controls

```{r}
#| fig-width: 12
#| fig-height: 5

tmp <- 
  se_16S |> 
  filter(sample_type == "Amplification positive control") |> 
  as_tibble() |> 
  group_by(.feature) |>
  mutate(max_rel_ab = max(rel_ab)) |> 
  ungroup() |> 
  filter(max_rel_ab > 0.1)

tmp |> 
  ggplot() +
  aes(x = sample_id, y = rel_ab, fill = .feature) +
  geom_col() +
  scale_fill_manual(
    str_c("Top ", tmp$.feature |> unique() |> length(), " taxa (based on max rel. ab.)"), 
    breaks = tmp$.feature |> unique(), 
    values = tmp$.feature |> unique() |> get_taxa_colors()
  ) +
  facet_grid(. ~ control_type, scales = "free_x", space = "free_x") +
  theme(
    strip.text.y = element_text(angle = 0),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    )
  
```


#### Positive controls


```{r}
#| fig-width: 15
#| fig-height: 5.5

tmp <- 
  se_16S |> 
  filter(sample_type == "Positive control") |> 
  as_tibble() |> 
  group_by(.feature) |>
  mutate(max_rel_ab = max(rel_ab)) |> 
  ungroup() |> 
  filter(max_rel_ab > 0.01)

tmp |> 
  ggplot() +
  aes(x = sample_id, y = rel_ab, fill = .feature) +
  geom_col() +
  scale_fill_manual(
    str_c("Top ", tmp$.feature |> unique() |> length(), " taxa (based on max rel. ab.)"), 
    breaks = tmp$.feature |> unique(), 
    values = tmp$.feature |> unique() |> get_taxa_colors()
  ) +
  facet_grid(. ~ control_type, scales = "free_x", space = "free_x") +
  theme(
    strip.text.y = element_text(angle = 0),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    )
  
```


That gives us an idea of the replicability and expected variability :)

## Replicates



```{r}
#| fig-width: 21
#| fig-height: 7

tmp <- 
  se_16S |> 
  as_tibble() |> 
  filter(sample_type == "Clinical sample") |> 
  group_by(pid, visit_code) |> mutate(n = sample_id |> unique() |> length()) |> ungroup() |>
  filter(n > 1) |> 
  filter(.feature %in% .feature[1:20])
  # group_by(.feature) |>
  # mutate(max_rel_ab = max(rel_ab)) |> 
  # ungroup() |> 
  # filter(max_rel_ab > 0.1)

tmp |> 
  ggplot() +
  aes(x = pool |> parse_number() |> factor(), y = rel_ab, fill = .feature, alpha = total_counts |> log10()) +
  geom_col() +
  scale_fill_manual(
    str_c("Top ", tmp$.feature |> unique() |> length(), " taxa (based on max rel. ab.)"), 
    breaks = tmp$.feature |> unique(), 
    values = tmp$.feature |> unique() |> get_taxa_colors()
  ) +
  facet_wrap(. ~ pid + visit_code, scales = "free_x", nrow = 3) +
  theme(
    strip.text.y = element_text(angle = 0),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    ) +
  xlab("pool")
  
```

Relatively good agreement between the replicates; for the longitudinal profiles below, when we have replicates, we'll use the replicate that had the most total reads.

:::callout-caution
@Joseph & co: is that what you intended with the replicates? Or was there a different (better) strategy?
:::

## Longitudinal profiles for randomized participants


```{r}

tmp <- 
  se_16S@colData |> 
  as.data.frame() |> 
  select(-any_of(c("randomized", "location"))) |> 
  dplyr::left_join(
    v |> select(pid, randomized, location) |> distinct(),
    by = join_by(pid)
  )

se_16S@colData$randomized <- tmp$randomized
se_16S@colData$location <- tmp$location

```

```{r}

n_taxa <- 20

tmp <- 
  se_16S |> 
  filter(randomized) |> 
  as_tibble() |> 
  filter(.feature %in% .feature[1:n_taxa]) 

selected_replicates <- 
  tmp |> 
  select(sample_id, pid, visit_code, pool, total_counts) |> 
  distinct() |> 
  arrange(pid, visit_code, -total_counts) |> 
  group_by(pid, visit_code) |>
  slice_head(n = 1) |> 
  ungroup() |> 
  group_by(visit_code) |> mutate(n = n()) |> ungroup() |> 
  filter(n > 20)
  

```

```{r}
#| fig-width: 15
#| fig-height: 20

tmp |> 
  filter(sample_id %in% selected_replicates$sample_id) |>
  ggplot() +
  aes(x = pid, y = rel_ab, fill = .feature) +
  geom_col() +
  scale_fill_manual(
    str_c("Top ", n_taxa, " taxa"), 
    breaks = tmp$.feature |> unique(), 
    values = tmp$.feature |> unique() |> get_taxa_colors()
  ) +
  facet_grid(visit_code ~ location, scales = "free_x", space = "free_x") +
  theme(
    strip.text.y = element_text(angle = 0),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    )
  
```


```{r}
#| fig-width: 12
#| fig-height: 25

tmp |> 
  filter(sample_id %in% selected_replicates$sample_id) |>
  ggplot() +
  aes(x = visit_code, y = rel_ab, fill = .feature) +
  geom_col() +
  scale_fill_manual(
    str_c("Top ", n_taxa, " taxa"), 
    breaks = tmp$.feature |> unique(), 
    values = tmp$.feature |> unique() |> get_taxa_colors()
  ) +
  facet_grid(location + pid ~ ., scales = "free_x", space = "free_x") +
  theme(
    strip.text.y = element_text(angle = 0),
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    )
  
```


## Save `SummarizedExperiment` objects

We save two `SE` objects to disk:

- `se_16S_raw`: one that has all the controls and replicates (current `se_16S` object)

- `se_16S_agg`: one that only has the clinical samples (if replicates, we keep the one with the most total counts) and the positive and negative controls (not the amplification controls). 

For `se_16S_agg`, we add the `uid` column (the VIBRANT cross-assay unique identifier) to the `colData` and as the `SE` "sample id" so that we can merge with the other assays.


> TODO: change the "replicate" strategy later if needed.


```{r}


# We only select the clinical samples and the positive and negative controls
se_16S_agg <- 
  se_16S |> 
  filter(
    sample_type %in% c("Clinical sample", "Positive control", "Negative control")
  ) 

# we pick the samples with the most total counts when there are replicates
selected_samples <- 
  se_16S_agg@colData |>
  as.data.frame() |> 
  as_tibble() |>
  filter(sample_type == "Clinical sample") |>
  select(sample_id, pid, visit_code, pool, total_counts) |> 
  distinct() |> 
  arrange(pid, visit_code, -total_counts) |> 
  group_by(pid, visit_code) |>
  slice_head(n = 1) |> 
  ungroup() |> 
  select(sample_id) |> 
  bind_rows(
    se_16S_agg@colData |>
      as.data.frame() |> 
      as_tibble() |>
      filter(sample_type != "Clinical sample") |> 
      select(sample_id)
  ) |> 
  distinct()
  
se_16S_agg <- se_16S_agg[, selected_samples$sample_id]

# We create the VIBRANT uid

se_16S_agg@colData$uid <- 
  ifelse(
    !is.na(se_16S_agg@colData$pid), 
    str_c(
      se_16S_agg@colData$pid, "_",
      se_16S_agg@colData$visit_code
    ), 
    se_16S_agg@colData$sample_id
  )

# we use these uids as the sample IDs
se_16S_agg <- 
  SummarizedExperiment(
    assays = list(
      counts = assay(se_16S_agg, "counts") |> set_colnames(se_16S_agg$uid),
      rel_ab = assay(se_16S_agg, "rel_ab") |> set_colnames(se_16S_agg$uid)
    ),
    rowData = rowData(se_16S_agg),
    colData = se_16S_agg@colData |> set_rownames(se_16S_agg$uid),
    metadata = se_16S_agg@metadata
  )
  
```

```{r}
se_16S_agg
```



```{r}

saveRDS(
  se_16S, 
  str_c(
    get_output_dir(data_source = data_source),  
    "04_se_16S_raw_", today() |> str_remove_all("-"), ".rds"
    )
  )

saveRDS(
  se_16S_agg, 
  str_c(
    get_output_dir(data_source = data_source),  
    "04_se_16S_agg_", today() |> str_remove_all("-"), ".rds"
    )
  )

```


